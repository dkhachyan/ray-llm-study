applications:
# - import_path: ray.serve.llm:build_openai_app
#   name: vLLM_engine
#   route_prefix: /
#   args:
#     llm_configs:
#       - model_loading_config:
#           model_id: "qwen-0.5b"
#           model_source: "Qwen/Qwen2.5-0.5B-Instruct"
- import_path: llm:app
  name: vLLM_engine
  route_prefix: /
  runtime_env:
    local_working_dir: ./
    env_vars:
      HF_TOKEN: ''
      MODEL_PATH: Qwen/Qwen2.5-7B-Instruct
      # MODEL_PATH: unsloth/Meta-Llama-3.1-8B-Instruct
      VLLM_USE_V1: '1'
    # pip:
    #   - openai==1.70.0
    #   - vllm[runai]
  deployments:
    - name: HelloWorld
      ray_actor_options:
        num_cpus: 1.0
        num_gpus: 1.0